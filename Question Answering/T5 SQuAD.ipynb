{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "93a03a65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Sep  7 15:57:00 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 440.118.02   Driver Version: 440.118.02   CUDA Version: 10.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce GTX 108...  On   | 00000000:51:00.0 Off |                  N/A |\n",
      "|  0%   31C    P8     9W / 250W |   3350MiB / 11178MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  GeForce GTX 108...  On   | 00000000:CB:00.0 Off |                  N/A |\n",
      "|  0%   33C    P8     9W / 250W |   3826MiB / 11178MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  GeForce GTX 108...  On   | 00000000:D5:00.0 Off |                  N/A |\n",
      "|  0%   31C    P8     9W / 250W |   4197MiB / 11178MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "887f8e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import json \n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "import textwrap\n",
    "from transformers import AdamW, T5ForConditionalGeneration, T5Tokenizer, get_linear_schedule_with_warmup\n",
    "import pytorch_lightning as pl\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4c925bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f33e0dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def squad_json_to_dataframe_train(input_file_path, record_path = ['data','paragraphs','qas','answers'],\n",
    "                           verbose = 1):\n",
    "    \"\"\"\n",
    "    input_file_path: path to the squad json file.\n",
    "    record_path: path to deepest level in json file default value is\n",
    "    ['data','paragraphs','qas','answers']\n",
    "    verbose: 0 to suppress it default is 1\n",
    "    \"\"\"\n",
    "    if verbose:\n",
    "        print(\"Reading the json file\")    \n",
    "    file = json.loads(open(input_file_path).read())\n",
    "    if verbose:\n",
    "        print(\"processing...\")\n",
    "    # parsing different level's in the json file\n",
    "    js = pd.json_normalize(file , record_path )\n",
    "    m = pd.json_normalize(file, record_path[:-1] )\n",
    "    r = pd.json_normalize(file,record_path[:-2])\n",
    "    \n",
    "    #combining it into single dataframe\n",
    "    idx = np.repeat(r['context'].values, r.qas.str.len())\n",
    "    ndx  = np.repeat(m['id'].values,m['answers'].str.len())\n",
    "    m['context'] = idx\n",
    "    js['q_idx'] = ndx\n",
    "    main = pd.concat([ m[['id','question','context']].set_index('id'),js.set_index('q_idx')],1,sort=False).reset_index()\n",
    "    main['c_id'] = main['context'].factorize()[0]\n",
    "    if verbose:\n",
    "        print(\"shape of the dataframe is {}\".format(main.shape))\n",
    "        print(\"Done\")\n",
    "    return main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "97ffb471",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading the json file\n",
      "processing...\n",
      "shape of the dataframe is (130319, 6)\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "input_file_path = 'train-v2.0.json'\n",
    "record_path = ['data','paragraphs','qas','answers']\n",
    "df = squad_json_to_dataframe_train(input_file_path=input_file_path,record_path=record_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "918b6884",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>question</th>\n",
       "      <th>context</th>\n",
       "      <th>text</th>\n",
       "      <th>answer_start</th>\n",
       "      <th>c_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56be85543aeaaa14008c9063</td>\n",
       "      <td>When did Beyonce start becoming popular?</td>\n",
       "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
       "      <td>in the late 1990s</td>\n",
       "      <td>269.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>56be85543aeaaa14008c9065</td>\n",
       "      <td>What areas did Beyonce compete in when she was...</td>\n",
       "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
       "      <td>singing and dancing</td>\n",
       "      <td>207.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>56be85543aeaaa14008c9066</td>\n",
       "      <td>When did Beyonce leave Destiny's Child and bec...</td>\n",
       "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
       "      <td>2003</td>\n",
       "      <td>526.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56bf6b0f3aeaaa14008c9601</td>\n",
       "      <td>In what city and state did Beyonce  grow up?</td>\n",
       "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
       "      <td>Houston, Texas</td>\n",
       "      <td>166.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56bf6b0f3aeaaa14008c9602</td>\n",
       "      <td>In which decade did Beyonce become famous?</td>\n",
       "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
       "      <td>late 1990s</td>\n",
       "      <td>276.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      index  \\\n",
       "0  56be85543aeaaa14008c9063   \n",
       "1  56be85543aeaaa14008c9065   \n",
       "2  56be85543aeaaa14008c9066   \n",
       "3  56bf6b0f3aeaaa14008c9601   \n",
       "4  56bf6b0f3aeaaa14008c9602   \n",
       "\n",
       "                                            question  \\\n",
       "0           When did Beyonce start becoming popular?   \n",
       "1  What areas did Beyonce compete in when she was...   \n",
       "2  When did Beyonce leave Destiny's Child and bec...   \n",
       "3      In what city and state did Beyonce  grow up?    \n",
       "4         In which decade did Beyonce become famous?   \n",
       "\n",
       "                                             context                 text  \\\n",
       "0  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...    in the late 1990s   \n",
       "1  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...  singing and dancing   \n",
       "2  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...                 2003   \n",
       "3  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...       Houston, Texas   \n",
       "4  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...           late 1990s   \n",
       "\n",
       "   answer_start  c_id  \n",
       "0         269.0     0  \n",
       "1         207.0     0  \n",
       "2         526.0     0  \n",
       "3         166.0     0  \n",
       "4         276.0     0  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "df3984c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5fca556e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((78138, 6), (8683, 6))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df, val_df = train_test_split(df, test_size=0.1)\n",
    "train_df.shape, val_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d3c96b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME= \"t5-base\"\n",
    "BATCH_SIZE = 8\n",
    "N_EPOCH= 2\n",
    "SOURCE_MAX_TOKEN_LEN= 300\n",
    "TARGET_MAX_TOKEN_LEN= 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "27724d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokernizer= T5Tokenizer.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4fd75b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SQuADDataset(Dataset):\n",
    "    def __init__(self, data: pd.DataFrame, \n",
    "                 tokernizer: T5Tokenizer, \n",
    "                 source_max_token_len: int = 256, \n",
    "                 target_max_token_len= 32):\n",
    "        \n",
    "        self.tokernizer= tokernizer\n",
    "        self.data= data\n",
    "        self.source_max_token_len= source_max_token_len\n",
    "        self.target_max_token_len= target_max_token_len\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index:int):\n",
    "        data_row = self.data.iloc[index]\n",
    "        source_encoding = self.tokernizer(\n",
    "            data_row['question'],\n",
    "            data_row['context'],\n",
    "            max_length=self.source_max_token_len,\n",
    "            padding= \"max_length\",\n",
    "            truncation= \"only_second\",\n",
    "            return_attention_mask=True,\n",
    "            add_special_tokens=True,\n",
    "            return_tensors= \"pt\"\n",
    "        )\n",
    "        \n",
    "        target_encoding = self.tokernizer(\n",
    "            data_row['text'],\n",
    "            max_length=self.target_max_token_len,\n",
    "            padding= \"max_length\",\n",
    "            truncation= True,\n",
    "            return_attention_mask=True,\n",
    "            add_special_tokens=True,\n",
    "            return_tensors= \"pt\"\n",
    "        )\n",
    "        \n",
    "        labels = target_encoding[\"input_ids\"]\n",
    "        labels[labels==0] = -100\n",
    "        \n",
    "        return (data_row[\"question\"],\n",
    "                data_row['context'],\n",
    "                data_row['text'],\n",
    "                source_encoding[\"input_ids\"].flatten(),\n",
    "                source_encoding[\"attention_mask\"].flatten(),\n",
    "                labels.flatten())\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4c69cf07",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset= SQuADDataset(data= train_df, \n",
    "                             tokernizer= tokernizer,\n",
    "                             source_max_token_len= SOURCE_MAX_TOKEN_LEN,\n",
    "                             target_max_token_len= TARGET_MAX_TOKEN_LEN)\n",
    "\n",
    "val_dataset= SQuADDataset(data= val_df, \n",
    "                             tokernizer= tokernizer,\n",
    "                             source_max_token_len= SOURCE_MAX_TOKEN_LEN,\n",
    "                             target_max_token_len= TARGET_MAX_TOKEN_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ecffaf79",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader= DataLoader(train_dataset,\n",
    "                         batch_size= BATCH_SIZE,\n",
    "                         shuffle= True,\n",
    "                         num_workers=4)\n",
    "\n",
    "val_loader= DataLoader(val_dataset,\n",
    "                         batch_size= BATCH_SIZE,\n",
    "                         shuffle= True,\n",
    "                         num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c27b7d21",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at t5-base were not used when initializing T5ForConditionalGeneration: ['decoder.block.0.layer.1.EncDecAttention.relative_attention_bias.weight']\n",
      "- This IS expected if you are initializing T5ForConditionalGeneration from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing T5ForConditionalGeneration from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model = T5ForConditionalGeneration.from_pretrained(MODEL_NAME).to(device)\n",
    "optimizer = AdamW(model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cd5a59f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a827b06b842406889d23a5d628f5015",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 0: Traingin:   0%|          | 0/9768 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c475ce57b4fb46e3b9e349b89e878742",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 0: Validation:   0%|          | 0/1086 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Train Loss: 0.354192273237458, Validation Loss: 0.27460871719108626\n",
      "Update Model at Epoch :0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8824771412cc44eda2198c0799fde1a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1: Traingin:   0%|          | 0/9768 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "312b948f981f4cb4a34ed3d0411e2e91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1: Validation:   0%|          | 0/1086 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Train Loss: 0.2526105786631773, Validation Loss: 0.2804432353793779\n"
     ]
    }
   ],
   "source": [
    "min_val_loss= float('inf')\n",
    "for epoch in range(N_EPOCH):    \n",
    "    model.train()\n",
    "    train_epoch_loss = 0\n",
    "    for question, context, answer_text, input_ids, attention_mask, labels in tqdm(train_loader, desc=f\"Epoch {epoch}: Traingin\"):\n",
    "        input_ids= input_ids.to(device)\n",
    "        attention_mask= attention_mask.to(device)\n",
    "        labels= labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output = model(input_ids= input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss, logits  =output.loss, output.logits\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_epoch_loss += loss.detach().item()\n",
    "    \n",
    "    train_epoch_loss /= len(train_loader)\n",
    "    \n",
    "    val_epoch_loss = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for question, context, answer_text, input_ids, attention_mask, labels in tqdm(val_loader, desc=f'Epoch {epoch}: Validation'):\n",
    "            input_ids= input_ids.to(device)\n",
    "            attention_mask= attention_mask.to(device)\n",
    "            labels= labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            output = model(input_ids= input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            loss, logits  =output.loss, output.logits\n",
    "\n",
    "            val_epoch_loss += loss.detach().item()\n",
    "    val_epoch_loss /= len(val_loader)\n",
    "    \n",
    "    print(f'Epoch: {epoch}, Train Loss: {train_epoch_loss}, Validation Loss: {val_epoch_loss}')\n",
    "    if min_val_loss > val_epoch_loss:\n",
    "        print(f\"Update Model at Epoch :{epoch}\")\n",
    "        torch.save({'state_dict': model.state_dict()}, 'model.tar')\n",
    "        min_val_loss = val_epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "840546a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at t5-base were not used when initializing T5ForConditionalGeneration: ['decoder.block.0.layer.1.EncDecAttention.relative_attention_bias.weight']\n",
      "- This IS expected if you are initializing T5ForConditionalGeneration from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing T5ForConditionalGeneration from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model = T5ForConditionalGeneration.from_pretrained(MODEL_NAME)\n",
    "checkpoint = torch.load('model.tar')\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "model= model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e0b91d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_answer(question):\n",
    "    source_encoding = tokernizer(\n",
    "            question['question'],\n",
    "            question['context'],\n",
    "            max_length=369,\n",
    "            padding= \"max_length\",\n",
    "            truncation= \"only_second\",\n",
    "            return_attention_mask=True,\n",
    "            add_special_tokens=True,\n",
    "            return_tensors= \"pt\"\n",
    "        ).to(device)\n",
    "    \n",
    "    generated_ids = model.generate(\n",
    "        input_ids=source_encoding['input_ids'],\n",
    "        attention_mask= source_encoding['attention_mask'],\n",
    "        num_beams= 1,\n",
    "        max_length=80,\n",
    "        length_penalty=1.0,\n",
    "        early_stopping=True,\n",
    "        use_cache= True\n",
    "    )\n",
    "    preds = [\n",
    "        tokernizer.decode(gen_id, skip_special_tokens=True, clean_up_tokenization_spaces=True)\n",
    "        for gen_id in generated_ids\n",
    "    ]\n",
    "    return \"\".join(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "643c1434",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context is: Multiracial Americans are Americans who have mixed ancestry of \"two or more races\". The term may also include Americans of mixed-race ancestry who self-identify with just one group culturally and socially (cf. the one-drop rule). In the 2010 US census, approximately 9 million individuals, or 2.9% of the population, self-identified as multiracial. There is evidence that an accounting by genetic ancestry would produce a higher number, but people live according to social and cultural identities, not DNA. Historical reasons, including slavery creating a racial caste and the European-American suppression of Native Americans, often led people to identify or be classified by only one ethnicity, generally that of the culture in which they were raised. Prior to the mid-20th century, many people hid their multiracial heritage because of racial discrimination against minorities. While many Americans may be biologically multiracial, they often do not know it or do not identify so culturally, any more than they maintain all the differing traditions of a variety of national ancestries.\n",
      "Question is: Which cultural do multicultural people usually identify with?\n",
      "Actual answer: , generally that of the culture in which they were raised.\n",
      "Predected answer: the culture in which they were raised\n"
     ]
    }
   ],
   "source": [
    "sample = val_df.iloc[890]\n",
    "print(f\"Context is: {sample['context']}\"\n",
    "      f\"\\nQuestion is: {sample['question']}\"\n",
    "      f\"\\nActual answer: {sample['text']}\"\n",
    "      f\"\\nPredected answer: {generate_answer(sample)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "28f78b11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context is: The largest private university in Uruguay, is also located in Montevideo. ORT Uruguay was first established as a non-profit organization in 1942, and was officially certified as a private university in September 1996, becoming the second private educational institution in the country to achieve that status.[citation needed] It is a member of World ORT, an international educational network founded in 1880 by the Jewish community in Saint Petersburg, Russia. The university has about 8,000 students, distributed among 5 faculties and institutes, mainly geared towards the sciences and technology/engineering. Its current rector as of 2010[update] is Dr. Jorge A. Grünberg.\n",
      "Question is: How many students does the ORT Uruguay university have?\n",
      "Actual answer: about 8,000\n",
      "Predected answer: 8,000\n"
     ]
    }
   ],
   "source": [
    "sample = val_df.iloc[600]\n",
    "print(f\"Context is: {sample['context']}\"\n",
    "      f\"\\nQuestion is: {sample['question']}\"\n",
    "      f\"\\nActual answer: {sample['text']}\"\n",
    "      f\"\\nPredected answer: {generate_answer(sample)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d91e6a20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context is: The Warsaw Treaty's organization was two-fold: the Political Consultative Committee handled political matters, and the Combined Command of Pact Armed Forces controlled the assigned multi-national forces, with headquarters in Warsaw, Poland. Furthermore, the Supreme Commander of the Unified Armed Forces of the Warsaw Treaty Organization which commands and controls all the military forces of the member countries was also a First Deputy Minister of Defense of the USSR, and the Chief of Combined Staff of the Unified Armed Forces of the Warsaw Treaty Organization was also a First Deputy Chief of the General Staff of the Armed Forces of the USSR. Therefore, although ostensibly an international collective security alliance, the USSR dominated the Warsaw Treaty armed forces.\n",
      "Question is: Despite being headquartered in Poland, the top-ranking operatives of the Warsaw Pact were from which country?\n",
      "Actual answer: the USSR\n",
      "Predected answer: USSR\n"
     ]
    }
   ],
   "source": [
    "sample = val_df.iloc[8]\n",
    "print(f\"Context is: {sample['context']}\"\n",
    "      f\"\\nQuestion is: {sample['question']}\"\n",
    "      f\"\\nActual answer: {sample['text']}\"\n",
    "      f\"\\nPredected answer: {generate_answer(sample)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "63cb0e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# these functions are heavily influenced by the HF squad_metrics.py script\n",
    "def normalize_text(s):\n",
    "    \"\"\"Removing articles and punctuation, and standardizing whitespace are all typical text processing steps.\"\"\"\n",
    "    import string, re\n",
    "\n",
    "    def remove_articles(text):\n",
    "        regex = re.compile(r\"\\b(a|an|the)\\b\", re.UNICODE)\n",
    "        return re.sub(regex, \" \", text)\n",
    "\n",
    "    def white_space_fix(text):\n",
    "        return \" \".join(text.split())\n",
    "\n",
    "    def remove_punc(text):\n",
    "        exclude = set(string.punctuation)\n",
    "        return \"\".join(ch for ch in text if ch not in exclude)\n",
    "\n",
    "    def lower(text):\n",
    "        return text.lower()\n",
    "\n",
    "    return white_space_fix(remove_articles(remove_punc(lower(s))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8f81bf56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_exact_match(prediction, truth):\n",
    "    return int(normalize_text(prediction) == normalize_text(truth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1fdfa3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_f1(prediction, truth):\n",
    "    pred_tokens = normalize_text(prediction).split()\n",
    "    truth_tokens = normalize_text(truth).split()\n",
    "    \n",
    "    # if either the prediction or the truth is no-answer then f1 = 1 if they agree, 0 otherwise\n",
    "    if len(pred_tokens) == 0 or len(truth_tokens) == 0:\n",
    "        return int(pred_tokens == truth_tokens)\n",
    "    \n",
    "    common_tokens = set(pred_tokens) & set(truth_tokens)\n",
    "    \n",
    "    # if there are no common tokens then f1 = 0\n",
    "    if len(common_tokens) == 0:\n",
    "        return 0\n",
    "    \n",
    "    prec = len(common_tokens) / len(pred_tokens)\n",
    "    rec = len(common_tokens) / len(truth_tokens)\n",
    "    \n",
    "    return 2 * (prec * rec) / (prec + rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "43d61767",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_loader= DataLoader(val_dataset,\n",
    "                         batch_size= 1,\n",
    "                         shuffle= True,\n",
    "                         num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "010669df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e898039c0be4ade9764288bf4f531bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/8683 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.8936549695611788, EM: 0.8009904410917885\n"
     ]
    }
   ],
   "source": [
    "EM= 0\n",
    "F1= 0\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for question, context, answer_text, input_ids, attention_mask, labels in tqdm(eval_loader, desc=f'Validation'):\n",
    "        sample = {\"context\": context[0], \"question\": question[0]}\n",
    "        EM += compute_exact_match(answer_text[0], generate_answer(sample))\n",
    "        F1 += compute_f1(answer_text[0], generate_answer(sample))\n",
    "    EM /= len(eval_loader)\n",
    "    F1 /= len(eval_loader)\n",
    "    print(f\"F1: {F1}, EM: {EM}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "822bd142",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
