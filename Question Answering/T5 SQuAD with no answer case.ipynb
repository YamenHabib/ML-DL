{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1726069c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Sep 13 20:22:33 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 440.118.02   Driver Version: 440.118.02   CUDA Version: 10.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce GTX 108...  On   | 00000000:51:00.0 Off |                  N/A |\n",
      "|  0%   34C    P8    14W / 250W |    803MiB / 11178MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  GeForce GTX 108...  On   | 00000000:CB:00.0 Off |                  N/A |\n",
      "| 36%   62C    P0    82W / 250W |     12MiB / 11178MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  GeForce GTX 108...  On   | 00000000:D5:00.0 Off |                  N/A |\n",
      "|  0%   32C    P8     8W / 250W |   6837MiB / 11178MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f3ab17e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import json \n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "import textwrap\n",
    "from transformers import AdamW, T5ForConditionalGeneration, T5Tokenizer, get_linear_schedule_with_warmup\n",
    "import pytorch_lightning as pl\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "21d848a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bde10d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def squad_json_to_dataframe_train(input_file_path, record_path = ['data','paragraphs','qas','answers'],\n",
    "                           verbose = 1):\n",
    "    \"\"\"\n",
    "    input_file_path: path to the squad json file.\n",
    "    record_path: path to deepest level in json file default value is\n",
    "    ['data','paragraphs','qas','answers']\n",
    "    verbose: 0 to suppress it default is 1\n",
    "    \"\"\"\n",
    "    if verbose:\n",
    "        print(\"Reading the json file\")    \n",
    "    file = json.loads(open(input_file_path).read())\n",
    "    if verbose:\n",
    "        print(\"processing...\")\n",
    "    # parsing different level's in the json file\n",
    "    js = pd.json_normalize(file , record_path )\n",
    "    m = pd.json_normalize(file, record_path[:-1] )\n",
    "    r = pd.json_normalize(file,record_path[:-2])\n",
    "    \n",
    "    #combining it into single dataframe\n",
    "    idx = np.repeat(r['context'].values, r.qas.str.len())\n",
    "    ndx  = np.repeat(m['id'].values,m['answers'].str.len())\n",
    "    m['context'] = idx\n",
    "    js['q_idx'] = ndx\n",
    "    main = pd.concat([ m[['id','question','context']].set_index('id'),js.set_index('q_idx')],1,sort=False).reset_index()\n",
    "    main['c_id'] = main['context'].factorize()[0]\n",
    "    if verbose:\n",
    "        print(\"shape of the dataframe is {}\".format(main.shape))\n",
    "        print(\"Done\")\n",
    "    return main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3138d4ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading the json file\n",
      "processing...\n",
      "shape of the dataframe is (130319, 6)\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "input_file_path = 'train-v2.0.json'\n",
    "record_path = ['data','paragraphs','qas','answers']\n",
    "df = squad_json_to_dataframe_train(input_file_path=input_file_path,record_path=record_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d9d76f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>question</th>\n",
       "      <th>context</th>\n",
       "      <th>text</th>\n",
       "      <th>answer_start</th>\n",
       "      <th>c_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56be85543aeaaa14008c9063</td>\n",
       "      <td>When did Beyonce start becoming popular?</td>\n",
       "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
       "      <td>in the late 1990s</td>\n",
       "      <td>269.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>56be85543aeaaa14008c9065</td>\n",
       "      <td>What areas did Beyonce compete in when she was...</td>\n",
       "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
       "      <td>singing and dancing</td>\n",
       "      <td>207.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>56be85543aeaaa14008c9066</td>\n",
       "      <td>When did Beyonce leave Destiny's Child and bec...</td>\n",
       "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
       "      <td>2003</td>\n",
       "      <td>526.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56bf6b0f3aeaaa14008c9601</td>\n",
       "      <td>In what city and state did Beyonce  grow up?</td>\n",
       "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
       "      <td>Houston, Texas</td>\n",
       "      <td>166.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56bf6b0f3aeaaa14008c9602</td>\n",
       "      <td>In which decade did Beyonce become famous?</td>\n",
       "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
       "      <td>late 1990s</td>\n",
       "      <td>276.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      index  \\\n",
       "0  56be85543aeaaa14008c9063   \n",
       "1  56be85543aeaaa14008c9065   \n",
       "2  56be85543aeaaa14008c9066   \n",
       "3  56bf6b0f3aeaaa14008c9601   \n",
       "4  56bf6b0f3aeaaa14008c9602   \n",
       "\n",
       "                                            question  \\\n",
       "0           When did Beyonce start becoming popular?   \n",
       "1  What areas did Beyonce compete in when she was...   \n",
       "2  When did Beyonce leave Destiny's Child and bec...   \n",
       "3      In what city and state did Beyonce  grow up?    \n",
       "4         In which decade did Beyonce become famous?   \n",
       "\n",
       "                                             context                 text  \\\n",
       "0  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...    in the late 1990s   \n",
       "1  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...  singing and dancing   \n",
       "2  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...                 2003   \n",
       "3  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...       Houston, Texas   \n",
       "4  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...           late 1990s   \n",
       "\n",
       "   answer_start  c_id  \n",
       "0         269.0     0  \n",
       "1         207.0     0  \n",
       "2         526.0     0  \n",
       "3         166.0     0  \n",
       "4         276.0     0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15abdbf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>question</th>\n",
       "      <th>context</th>\n",
       "      <th>text</th>\n",
       "      <th>answer_start</th>\n",
       "      <th>c_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>130314</th>\n",
       "      <td>5a7e070b70df9f001a875439</td>\n",
       "      <td>Physics has broadly agreed on the definition o...</td>\n",
       "      <td>The term \"matter\" is used throughout physics i...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130315</th>\n",
       "      <td>5a7e070b70df9f001a87543a</td>\n",
       "      <td>Who coined the term partonic matter?</td>\n",
       "      <td>The term \"matter\" is used throughout physics i...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130316</th>\n",
       "      <td>5a7e070b70df9f001a87543b</td>\n",
       "      <td>What is another name for anti-matter?</td>\n",
       "      <td>The term \"matter\" is used throughout physics i...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130317</th>\n",
       "      <td>5a7e070b70df9f001a87543c</td>\n",
       "      <td>Matter usually does not need to be used in con...</td>\n",
       "      <td>The term \"matter\" is used throughout physics i...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130318</th>\n",
       "      <td>5a7e070b70df9f001a87543d</td>\n",
       "      <td>What field of study has a variety of unusual c...</td>\n",
       "      <td>The term \"matter\" is used throughout physics i...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19028</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           index  \\\n",
       "130314  5a7e070b70df9f001a875439   \n",
       "130315  5a7e070b70df9f001a87543a   \n",
       "130316  5a7e070b70df9f001a87543b   \n",
       "130317  5a7e070b70df9f001a87543c   \n",
       "130318  5a7e070b70df9f001a87543d   \n",
       "\n",
       "                                                 question  \\\n",
       "130314  Physics has broadly agreed on the definition o...   \n",
       "130315               Who coined the term partonic matter?   \n",
       "130316              What is another name for anti-matter?   \n",
       "130317  Matter usually does not need to be used in con...   \n",
       "130318  What field of study has a variety of unusual c...   \n",
       "\n",
       "                                                  context text  answer_start  \\\n",
       "130314  The term \"matter\" is used throughout physics i...  NaN           NaN   \n",
       "130315  The term \"matter\" is used throughout physics i...  NaN           NaN   \n",
       "130316  The term \"matter\" is used throughout physics i...  NaN           NaN   \n",
       "130317  The term \"matter\" is used throughout physics i...  NaN           NaN   \n",
       "130318  The term \"matter\" is used throughout physics i...  NaN           NaN   \n",
       "\n",
       "         c_id  \n",
       "130314  19028  \n",
       "130315  19028  \n",
       "130316  19028  \n",
       "130317  19028  \n",
       "130318  19028  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e97f4fec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((117287, 6), (13032, 6))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df, val_df = train_test_split(df, test_size=0.1)\n",
    "train_df.shape, val_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2182f7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME= \"t5-base\"\n",
    "BATCH_SIZE = 10\n",
    "N_EPOCH= 4\n",
    "SOURCE_MAX_TOKEN_LEN= 300\n",
    "TARGET_MAX_TOKEN_LEN= 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "53bf5c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer= T5Tokenizer.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c08992bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32100"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70709dec",
   "metadata": {},
   "source": [
    "### Adding our special answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "20326192",
   "metadata": {},
   "outputs": [],
   "source": [
    "NO_ANSWER = '[NO_ANSWER]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8406803b",
   "metadata": {},
   "outputs": [],
   "source": [
    "special_tokens_dict = {'additional_special_tokens': [NO_ANSWER]}\n",
    "len_added_tokens= tokenizer.add_special_tokens(special_tokens_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4a586427",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at t5-base were not used when initializing T5ForConditionalGeneration: ['decoder.block.0.layer.1.EncDecAttention.relative_attention_bias.weight']\n",
      "- This IS expected if you are initializing T5ForConditionalGeneration from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing T5ForConditionalGeneration from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model = T5ForConditionalGeneration.from_pretrained(MODEL_NAME).to(device)\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "optimizer = AdamW(model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "93fa4b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SQuADDataset(Dataset):\n",
    "    def __init__(self, data: pd.DataFrame, \n",
    "                 tokenizer: T5Tokenizer, \n",
    "                 source_max_token_len: int = 256, \n",
    "                 target_max_token_len= 32):\n",
    "        \n",
    "        self.tokenizer= tokenizer\n",
    "        self.data= data\n",
    "        self.source_max_token_len= source_max_token_len\n",
    "        self.target_max_token_len= target_max_token_len\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index:int):\n",
    "        data_row = self.data.iloc[index]\n",
    "        source_encoding = self.tokenizer(\n",
    "            data_row['question'],\n",
    "            data_row['context'],\n",
    "            max_length=self.source_max_token_len,\n",
    "            padding= \"max_length\",\n",
    "            truncation= \"only_second\",\n",
    "            return_attention_mask=True,\n",
    "            add_special_tokens=True,\n",
    "            return_tensors= \"pt\"\n",
    "        )\n",
    "        answer_text = NO_ANSWER if pd.isnull(data_row['text']) else data_row['text']\n",
    "        target_encoding = self.tokenizer(\n",
    "                answer_text,\n",
    "                max_length=self.target_max_token_len,\n",
    "                padding= \"max_length\",\n",
    "                truncation= True,\n",
    "                return_attention_mask=True,\n",
    "                add_special_tokens=True,\n",
    "                return_tensors= \"pt\"\n",
    "            )\n",
    "        \n",
    "        labels = target_encoding[\"input_ids\"]\n",
    "        labels[labels==0] = -100\n",
    "        \n",
    "        return (data_row[\"question\"],\n",
    "                data_row['context'],\n",
    "                answer_text,\n",
    "                source_encoding[\"input_ids\"].flatten(),\n",
    "                source_encoding[\"attention_mask\"].flatten(),\n",
    "                labels.flatten())\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "86a7ec02",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset= SQuADDataset(data= train_df, \n",
    "                             tokenizer= tokenizer,\n",
    "                             source_max_token_len= SOURCE_MAX_TOKEN_LEN,\n",
    "                             target_max_token_len= TARGET_MAX_TOKEN_LEN)\n",
    "\n",
    "val_dataset= SQuADDataset(data= val_df, \n",
    "                             tokenizer= tokenizer,\n",
    "                             source_max_token_len= SOURCE_MAX_TOKEN_LEN,\n",
    "                             target_max_token_len= TARGET_MAX_TOKEN_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0f21e53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader= DataLoader(train_dataset,\n",
    "                         batch_size= BATCH_SIZE,\n",
    "                         shuffle= True,\n",
    "                         num_workers=4)\n",
    "\n",
    "val_loader= DataLoader(val_dataset,\n",
    "                         batch_size= BATCH_SIZE,\n",
    "                         shuffle= True,\n",
    "                         num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8ec375f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73c502ac898649989a35b94ec74a60b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 0: Traingin:   0%|          | 0/11729 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11b92bf789c74064b3858d7cb9c34ef7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 0: Validation:   0%|          | 0/1304 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Train Loss: 0.6466876193944557, Validation Loss: 0.3474362410288561\n",
      "Update Model at Epoch :0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0f553e2f8564dd5bd53c1dc833bd962",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1: Traingin:   0%|          | 0/11729 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc4e256566774e67af02d0fff909f931",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1: Validation:   0%|          | 0/1304 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Train Loss: 0.3533726451985658, Validation Loss: 0.3349837488873342\n",
      "Update Model at Epoch :1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8159855ae1df42b0902fcf9189fa4bf2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2: Traingin:   0%|          | 0/11729 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83e9c4b2c72a46cdaf6262d93197d65f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2: Validation:   0%|          | 0/1304 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Train Loss: 0.2617824972867321, Validation Loss: 0.339365730365664\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "850085ad0c1e4cc499c41f2c0b9da306",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3: Traingin:   0%|          | 0/11729 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "605356c3409541e997a40176bea7568a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3: Validation:   0%|          | 0/1304 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3, Train Loss: 0.2047569936936835, Validation Loss: 0.3534717353459368\n"
     ]
    }
   ],
   "source": [
    "min_val_loss= float('inf')\n",
    "for epoch in range(N_EPOCH):    \n",
    "    model.train()\n",
    "    train_epoch_loss = 0\n",
    "    for question, context, answer_text, input_ids, attention_mask, labels in tqdm(train_loader, desc=f\"Epoch {epoch}: Traingin\"):\n",
    "        input_ids= input_ids.to(device)\n",
    "        attention_mask= attention_mask.to(device)\n",
    "        labels= labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output = model(input_ids= input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss, logits  =output.loss, output.logits\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_epoch_loss += loss.detach().item()\n",
    "    \n",
    "    train_epoch_loss /= len(train_loader)\n",
    "    \n",
    "    val_epoch_loss = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for question, context, answer_text, input_ids, attention_mask, labels in tqdm(val_loader, desc=f'Epoch {epoch}: Validation'):\n",
    "            input_ids= input_ids.to(device)\n",
    "            attention_mask= attention_mask.to(device)\n",
    "            labels= labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            output = model(input_ids= input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            loss, logits  =output.loss, output.logits\n",
    "\n",
    "            val_epoch_loss += loss.detach().item()\n",
    "    val_epoch_loss /= len(val_loader)\n",
    "    \n",
    "    print(f'Epoch: {epoch}, Train Loss: {train_epoch_loss}, Validation Loss: {val_epoch_loss}')\n",
    "    if min_val_loss > val_epoch_loss:\n",
    "        print(f\"Update Model at Epoch :{epoch}\")\n",
    "        torch.save({'state_dict': model.state_dict()}, 'model.tar')\n",
    "        min_val_loss = val_epoch_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47cc2b29",
   "metadata": {},
   "source": [
    "## Evaluate Our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "18c19295",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at t5-base were not used when initializing T5ForConditionalGeneration: ['decoder.block.0.layer.1.EncDecAttention.relative_attention_bias.weight']\n",
      "- This IS expected if you are initializing T5ForConditionalGeneration from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing T5ForConditionalGeneration from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model = T5ForConditionalGeneration.from_pretrained(MODEL_NAME)\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "checkpoint = torch.load('model.tar')\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "model= model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "95acbacf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# these functions are heavily influenced by the HF squad_metrics.py script\n",
    "def normalize_text(s):\n",
    "    \"\"\"Removing articles and punctuation, and standardizing whitespace are all typical text processing steps.\"\"\"\n",
    "    import string, re\n",
    "\n",
    "    def remove_articles(text):\n",
    "        regex = re.compile(r\"\\b(a|an|the)\\b\", re.UNICODE)\n",
    "        return re.sub(regex, \" \", text)\n",
    "\n",
    "    def white_space_fix(text):\n",
    "        return \" \".join(text.split())\n",
    "\n",
    "    def remove_punc(text):\n",
    "        exclude = set(string.punctuation)\n",
    "        return \"\".join(ch for ch in text if ch not in exclude)\n",
    "\n",
    "    def lower(text):\n",
    "        return text.lower()\n",
    "\n",
    "    return white_space_fix(remove_articles(remove_punc(lower(s))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f87f480d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_exact_match(prediction, truth):\n",
    "    return int(normalize_text(prediction) == normalize_text(truth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "272d26c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_f1(prediction, truth):\n",
    "    pred_tokens = normalize_text(prediction).split()\n",
    "    truth_tokens = normalize_text(truth).split()\n",
    "    \n",
    "    # if either the prediction or the truth is no-answer then f1 = 1 if they agree, 0 otherwise\n",
    "    if len(pred_tokens) == 0 or len(truth_tokens) == 0:\n",
    "        return int(pred_tokens == truth_tokens)\n",
    "    \n",
    "    common_tokens = set(pred_tokens) & set(truth_tokens)\n",
    "    \n",
    "    # if there are no common tokens then f1 = 0\n",
    "    if len(common_tokens) == 0:\n",
    "        return 0\n",
    "    \n",
    "    prec = len(common_tokens) / len(pred_tokens)\n",
    "    rec = len(common_tokens) / len(truth_tokens)\n",
    "    \n",
    "    return 2 * (prec * rec) / (prec + rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2bab39bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_loader= DataLoader(val_dataset,\n",
    "                         batch_size= 1,\n",
    "                         shuffle= False,\n",
    "                         num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f555e02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_answer(question):\n",
    "    source_encoding = tokenizer(\n",
    "            question['question'],\n",
    "            question['context'],\n",
    "            max_length=369,\n",
    "            padding= \"max_length\",\n",
    "            truncation= \"only_second\",\n",
    "            return_attention_mask=True,\n",
    "            add_special_tokens=True,\n",
    "            return_tensors= \"pt\"\n",
    "        ).to(device)\n",
    "    \n",
    "    generated_ids = model.generate(\n",
    "        input_ids=source_encoding['input_ids'],\n",
    "        attention_mask= source_encoding['attention_mask'],\n",
    "        num_beams= 1,\n",
    "        max_length=80,\n",
    "        length_penalty=1.0,\n",
    "        early_stopping=True,\n",
    "        use_cache= True\n",
    "    )\n",
    "    preds = [\n",
    "        tokenizer.decode(gen_id, skip_special_tokens=False, clean_up_tokenization_spaces=True)\n",
    "        for gen_id in generated_ids\n",
    "    ]\n",
    "    predicted_answer= \"\".join(preds)\n",
    "    predicted_answer= predicted_answer.replace('</s>', '')\n",
    "    predicted_answer= predicted_answer.replace('<pad>', '')\n",
    "    return predicted_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a7d4ef3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70b65adb490b41de9269dab08d98292d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/13032 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.8058683708079691, EM: 0.7328882750153468\n"
     ]
    }
   ],
   "source": [
    "EM= 0\n",
    "F1= 0\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for question, context, answer_text, input_ids, attention_mask, labels in tqdm(eval_loader, desc=f'Validation'):\n",
    "        sample = {\"context\": context[0], \"question\": question[0]}\n",
    "        predicted_answer= generate_answer(sample)\n",
    "        \n",
    "        EM += compute_exact_match(answer_text[0], predicted_answer)\n",
    "        F1 += compute_f1(answer_text[0], predicted_answer)\n",
    "    EM /= len(eval_loader)\n",
    "    F1 /= len(eval_loader)\n",
    "    print(f\"F1: {F1}, EM: {EM}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c79c1eec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context is: Copper is an essential trace element in plants and animals, but not some microorganisms. The human body contains copper at a level of about 1.4 to 2.1 mg per kg of body mass. Stated differently, the RDA for copper in normal healthy adults is quoted as 0.97 mg/day and as 3.0 mg/day. Copper is absorbed in the gut, then transported to the liver bound to albumin. After processing in the liver, copper is distributed to other tissues in a second phase. Copper transport here involves the protein ceruloplasmin, which carries the majority of copper in blood. Ceruloplasmin also carries copper that is excreted in milk, and is particularly well-absorbed as a copper source. Copper in the body normally undergoes enterohepatic circulation (about 5 mg a day, vs. about 1 mg per day absorbed in the diet and excreted from the body), and the body is able to excrete some excess copper, if needed, via bile, which carries some copper out of the liver that is not then reabsorbed by the intestine.\n",
      "Question is: What is the level of copper in gold?\n",
      "Actual answer: nan\n",
      "Predected answer:  [NO_ANSWER] \n"
     ]
    }
   ],
   "source": [
    "sample = val_df.iloc[890]\n",
    "print(f\"Context is: {sample['context']}\"\n",
    "      f\"\\nQuestion is: {sample['question']}\"\n",
    "      f\"\\nActual answer: {sample['text']}\"\n",
    "      f\"\\nPredected answer: {generate_answer(sample)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b36883b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context is: The second Digimon series is direct continuation of the first one, and began airing on April 2, 2000. Three years later, with most of the original DigiDestined now in high school at age fourteen, the Digital World was supposedly secure and peaceful. However, a new evil has appeared in the form of the Digimon Emperor (Digimon Kaiser) who as opposed to previous enemies is a human just like the DigiDestined. The Digimon Emperor has been enslaving Digimon with Dark Rings and Control Spires and has somehow made regular Digivolution impossible. However, five set Digi-Eggs with engraved emblems had been appointed to three new DigiDestined along with T.K. and Kari, two of the DigiDestined from the previous series. This new evolutionary process, dubbed Armor Digivolution helps the new DigiDestined to defeat evil lurking in the Digital World. Eventually, the DigiDestined defeat the Digimon Emperor, more commonly known as Ken Ichijouji on Earth, only with the great sacrifice of Ken's own Digimon, Wormmon. Just when things were thought to be settled, new Digimon enemies made from the deactivated Control Spires start to appear and cause trouble in the Digital World. To atone for his past mistakes, Ken joins the DigiDestined, being a DigiDestined himself, with his Partner Wormmon revived to fight against them. They soon save countries including France and Australia from control spires and defeat MaloMyotismon (BelialVamdemon), the digivolved form of Myotismon (Vamdemon) from the previous series. They stop the evil from destroying the two worlds, and at the end, every person on Earth gains their own Digimon partner.\n",
      "Question is: Who is the Digimon Empress?\n",
      "Actual answer: nan\n",
      "Predected answer:  [NO_ANSWER] \n"
     ]
    }
   ],
   "source": [
    "sample = val_df.iloc[600]\n",
    "print(f\"Context is: {sample['context']}\"\n",
    "      f\"\\nQuestion is: {sample['question']}\"\n",
    "      f\"\\nActual answer: {sample['text']}\"\n",
    "      f\"\\nPredected answer: {generate_answer(sample)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "05c6168b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context is: Twilight Princess received the awards for Best Artistic Design, Best Original Score, and Best Use of Sound from IGN for its GameCube version. Both IGN and Nintendo Power gave Twilight Princess the awards for Best Graphics and Best Story. Twilight Princess received Game of the Year awards from GameTrailers, 1UP.com, Electronic Gaming Monthly, Game Informer, Games Radar, GameSpy, Spacey Awards, X-Play and Nintendo Power. It was also given awards for Best Adventure Game from the Game Critics Awards, X-Play, IGN, GameTrailers, 1UP.com, and Nintendo Power. The game was considered the Best Console Game by the Game Critics Awards and GameSpy. The game placed 16th in Official Nintendo Magazine's list of the 100 Greatest Nintendo Games of All Time. IGN ranked the game as the 4th-best Wii game. Nintendo Power ranked the game as the third-best game to be released on a Nintendo system in the 2000s decade.\n",
      "Question is: What 2 critics gave Game Radar awards for Best Graphics and Best Story?\n",
      "Actual answer: nan\n",
      "Predected answer:  [NO_ANSWER] \n"
     ]
    }
   ],
   "source": [
    "sample = val_df.iloc[8]\n",
    "print(f\"Context is: {sample['context']}\"\n",
    "      f\"\\nQuestion is: {sample['question']}\"\n",
    "      f\"\\nActual answer: {sample['text']}\"\n",
    "      f\"\\nPredected answer: {generate_answer(sample)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d3c3fe56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context is: In a 2009 case, Netbula, LLC v. Chordiant Software Inc., defendant Chordiant filed a motion to compel Netbula to disable the robots.txt file on its web site that was causing the Wayback Machine to retroactively remove access to previous versions of pages it had archived from Nebula's site, pages that Chordiant believed would support its case.\n",
      "Question is: What did Chordiant request that the court deactivate on Netbula's website?\n",
      "Actual answer: the robots.txt file\n",
      "Predected answer:  robots.txt\n"
     ]
    }
   ],
   "source": [
    "sample = val_df.iloc[456]\n",
    "print(f\"Context is: {sample['context']}\"\n",
    "      f\"\\nQuestion is: {sample['question']}\"\n",
    "      f\"\\nActual answer: {sample['text']}\"\n",
    "      f\"\\nPredected answer: {generate_answer(sample)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "3b7d6a28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context is: In 2005, the constitution was put into effect. There is still much debate in the country about the constitutional reforms. From the early seventies, there was active resistance to the royal hegemony. Despite complaints from progressive formations, support for the monarchy and the current political system remains strong among the majority of the population.[citation needed] Submissions were made by citizens around the country to commissions, including the constitutional draft committee, indicating that they would prefer to maintain the current situation.\n",
      "Question is: When did people begin to disputre royal hegenomy in Swaziland?\n",
      "Actual answer: the early seventies\n",
      "Predected answer:  early seventies\n"
     ]
    }
   ],
   "source": [
    "sample = val_df.iloc[86]\n",
    "print(f\"Context is: {sample['context']}\"\n",
    "      f\"\\nQuestion is: {sample['question']}\"\n",
    "      f\"\\nActual answer: {sample['text']}\"\n",
    "      f\"\\nPredected answer: {generate_answer(sample)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "080ca8e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context is: Catholic missionary Father A. Erdland, from the Sacred Heart Jesu Society based in Hiltrup, Germany, lived on Jaluit from around 1904 to 1914. He was very interested in the islands and conducted considerable research on the Marshallese culture and language. He published a 376-page monograph on the islands in 1914. Father H. Linckens, another missionary from the Sacred Heart of Jesu Society visited the Marshall Islands in 1904 and 1911 for several weeks. He published a small work in 1912 about the Catholic mission activities and the people of the Marshall Islands.\n",
      "Question is: In what year was Father Linckens' last visit to the Marshalls?\n",
      "Actual answer: 1911\n",
      "Predected answer:  1911\n"
     ]
    }
   ],
   "source": [
    "sample = val_df.iloc[8979]\n",
    "print(f\"Context is: {sample['context']}\"\n",
    "      f\"\\nQuestion is: {sample['question']}\"\n",
    "      f\"\\nActual answer: {sample['text']}\"\n",
    "      f\"\\nPredected answer: {generate_answer(sample)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "026f809b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
